
\subsection{Lojasiewicz type inequality - Convergence of the continuous flow}\label{sec:Lojasiewicz_inequality}

Here we would like to derive an inequality between the time derivative of the Lyapunov functional $\mathcal{F}$ along its gradient flow $t\mapsto \rho_t$. For this purpose we first introduce the weighted negative Sobolev distance \manote{cite villani and peyre and Mroueh}:
\begin{align}\label{eq:neg_sobolev}
	\Vert \nu - \mu \Vert_{\dot{H}^{-1}(\nu)} = \sup_{\substack{ f\in W_0^{1,2}(\nu), \; \nu(\Vert \nabla f \Vert^2) \leq 1 }} \vert \nu(f)-\mu(f)\vert 
\end{align}
Where $W_0^{1,2}(\nu)$ is the space $1$ order Sobolev functions with functions vanishing at the boundary of the domain.
The distance defined in \cref{eq:neg_sobolev} plays a fundamental role in dynamic optimal transport as it linearizes the $W_2$ distance when $\mu$ is arbitrarily close to $\nu$. It can also be seen as the minimum kinetic energy needed to advect the mass $\nu$ to $\mu$. However, this quantity might be infinite \manote{say exactly when it is finite} and one of the key problems would be to control its value during the evolution of the flow. More precisely we will rely on the following statement:
\begin{align}\label{eq:bounded_neg_sobolev}
	\Vert \nu_t  - \mu \Vert_{\dot{H}^{-1}(\nu_t)} \leq C \qquad \forall t\geq 0.
\end{align} 
where $\nu_t$ is defined by the gradient flow and $\mu$ is the target distribution. When \cref{eq:bounded_neg_sobolev}  holds, we have the following proposition:
\begin{proposition}\label{prop:lojasiewicz}
	When \cref{eq:bounded_neg_sobolev} holds, the following inequality is then satisfied at all times:
	\begin{align}\label{eq:PL_type_inequality}
		\Vert \nabla f_t \Vert_{L_2(\nu_t)} \geq \frac{1}{C} \Vert f_t \Vert^2_{\mathcal{H}} \qquad \forall t\geq 0.
	\end{align}
	Then $t\mapsto \mathcal{F}(\nu_t)$ converges to $0$ with a rate of convergence given by:
	\begin{align}
	\mathcal{F}(\nu_t)\leq \frac{1}{\mathcal{F}(\nu_0)^{-1} + \frac{4t}{C}}
	\end{align}
\end{proposition}



All the difficulty is to see now when \cref{eq:bounded_neg_sobolev} holds. One possible strategy would be to start from initial $\nu_0$ such that $\Vert \nu_0  - \mu \Vert_{\dot{H}^{-1}(\nu_0)} \leq C $  for some finite positive value $C$ and then show that this property is preserved during the dynamics. It is also possible to have a time depended constant $C_t$ as long as its growth is such that:
\begin{align}
	\lim_{t\rightarrow +\infty} \int_0^t C_s^{-1}\diff s = +\infty
\end{align}
For instance $C_t$ could have up to a linear growth in time. In this case the decay of $\F(\nu_t)$ will no longer be in $\frac{1}{t}$ but only in $\frac{1}{\log(t)}$ \manote{This seems unlikely if we end up having convergence of $\nu_t$, but who nows.}.
One possible promising condition for \cref{eq:bounded_neg_sobolev} to hold would be if $\mu \ll \nu_0$ and if this property is preserved during the dynamics.


 
 
 
 
 
 \subsection{Convergence of the space discretized flow - Sample-based setting}
 
 Given samples $(u_1, \dots, u_N)\sim \mu, (v_1, \dots, v_N)\sim \nu_t$, the gradient of $f_{\mu, \nu_t}$ can be easily estimated by:
\begin{equation}
\nabla f_{\widehat{\mu},\widehat{\nu_t}}(z)= \frac{1}{N}\sum_{i=1}^{N}\nabla_{z}k(u_i,z) -\frac{1}{N}\sum_{i=1}^{N}\nabla_{z}k(v_i,z) 
\end{equation}
where $\widehat{ \mu}=\sum_{j=1}^{N}\delta_{u_i}$ and $\widehat{ \nu_t}=\sum_{j=1}^{N}\delta_{v_i}$. However, we do not have access to $(v_1, \dots, v_N)\sim \nu_t$ at each time $t$. A common approach (sometimes referred to as \textit{mean-field interaction} in mathematical physics and stochastic analysis) is to consider the following system of $n$ interacting particles $(X_t^{1,N}, X_t^{2,N}, \dots, X_t^{N,N})$: 
\begin{equation}\label{eq:sample_based_process}
%X_t^{j,N}=X_{0}^j+\int_{0}^t \nabla f_{\widehat{\mu}, \nu_s^N}(X_s^{j,N})ds \quad \text{where } \nu_t^N=\frac{1}{N} \sum_{i=1}^N \delta_{X_t^{j,N}}
\dot{X}_t^{j,N}=-\nabla f_{\widehat{\mu}, \nu_t^N}(X_t^{j,N}) \text{ where } \nu_t^N=\frac{1}{N} \sum_{i=1}^N \delta_{X_t^{j,N}}
\end{equation}
%&\forall s \in [0,T]\;,\quad \widehat{\rho}_s^n=\sum_{j=1}^{n} \delta_{\widehat{X}_s^{j,n}} \text{ denotes the empirical measure } 
The following proposition, whose proof is deferred to the Appendix, quantifies the distance between the target distribution and the one of the latter particle system.
%Notice that the coefficient $\nabla f_{\mu, \nu_t}$ in \eqref{eq:mcKean_Vlasov_process} has been replaced by $\nabla f_{\widehat{\mu}, \widehat{\nu_t}}$ where $\widehat{\nu}_t$ is the density of the process defined in \eqref{eq:sample_based_process}. 
\begin{proposition}\label{prop:sample_based_rates}
	\aknote{the bound could be refined, and there are few mild assumptions - see the proof for details/discussion. In particular, by taking $t=\sqrt{n}$, we could get a $\mathcal{O(\frac{1}{\sqrt{N}})}$ bound.} Let $\nu_t^N$, be the distribution of the particle system \eqref{eq:sample_based_process}. We have, for all $t>0$:
	\begin{equation}
	MMD^2(\mu,\nu_t^N)\le \frac{C_1(t)}{N}+ \frac{C_2}{N} + \frac{C_3}{t}
	\end{equation}
\end{proposition}
Let us also introduce the Euler discretizations with time-step $h > 0$ of the SDE \eqref{eq:mcKean_Vlasov_process} (with $\widehat{ \mu}$ as a target distribution) and the particle system:
\begin{equation}\label{eq:discret_time}
X_{m+1}=X_m - \gamma \nabla f_{\widehat{\mu}, \nu_m}(X_m) \end{equation}
\begin{equation}\label{eq:sample_based_discret_time}
X_{m+1}^{j,N}=X_{m}^{j,N}- \gamma \nabla f_{\widehat{\mu}, \nu_m^N}(X_m^{j,N}) \quad \text{where } \nu_m^N=\frac{1}{N} \sum_{i=1}^N \delta_{X_m^{j,N}}
\end{equation}
\begin{proposition}%\label{prop:sample_based_rates}
	Let $\nu_m$,$\nu_m^N$, be the distributions of \eqref{eq:discret_time} and the particle system \eqref{eq:sample_based_discret_time}. We have, for all $t>0$:\aknote{from Jourdain 2019. Unfortunately I think it's hard to inherit this result in the noisy case}
	\begin{equation}
	MMD^2(\nu_m,\nu_m^N)\le \frac{C_1(t)}{N}
	\end{equation}
\end{proposition}

\begin{remark}
	Two settings are usually encountered in the sampling literature: \textit{density-based}, i.e. the target $\mu$ is known up to a constant, or \textit{sample-based}, i.e. we only have access to a set of samples $X \sim \mu$.
	The Unadjusted Langevin Algorithm (ULA), which involves a time-discretized version of the Langevin diffusion (see \cref{rk:kl_flow}), seems much more suitable for first setting, since it only requires the knowledge of $\nabla \log \mu$, whereas our algorithm requires the knowledge of $\mu$ (since $\nabla f_{\mu, \nu_t}$ involves an integration over $\mu$). However, in the sample-based setting, it may be difficult to adapt the ULA algorithm, since it would require firstly to estimate $\nabla \log(\mu)$ based on a set of samples of $\mu$, before plugging this estimate in the update of the algorithm. This problem, sometimes referred to as \textit{score estimation} in the literature, has been the subject of a lot of work but remains hard especially in high dimensions (see \cite{sutherland2017efficient,li2018gradient,shi2018spectral}). In contrast, the discretized flow of the $MMD^2$ presented in this section seems naturally adapted to the sample-based setting.
\end{remark}
 








