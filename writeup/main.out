\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Preliminaries}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Maximum Mean Discrepancy}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Training neural networks as flow of the MMD}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Background on optimal transport}{section.2}% 5
\BOOKMARK [3][-]{subsubsection.2.3.1}{2-Wasserstein geometry}{subsection.2.3}% 6
\BOOKMARK [3][-]{subsubsection.2.3.2}{Gradient flows on the space of probability measures}{subsection.2.3}% 7
\BOOKMARK [1][-]{section.3}{MMD gradient flow}{}% 8
\BOOKMARK [2][-]{subsection.3.1}{MMD as a free energy}{section.3}% 9
\BOOKMARK [2][-]{subsection.3.2}{Lambda displacement convexity of the MMD}{section.3}% 10
\BOOKMARK [2][-]{subsection.3.3}{Lojasiewicz type inequality - Convergence of the continuous flow}{section.3}% 11
\BOOKMARK [2][-]{subsection.3.4}{Noisy MMD flow}{section.3}% 12
\BOOKMARK [1][-]{section.4}{Discretizing the MMD gradient Flow}{}% 13
\BOOKMARK [2][-]{subsection.4.1}{Convergence of the time-discretized flow}{section.4}% 14
\BOOKMARK [2][-]{subsection.4.2}{Convergence of the space discretized flow - Sample-based setting}{section.4}% 15
\BOOKMARK [1][-]{section.5}{Conclusion}{}% 16
\BOOKMARK [1][-]{section.6}{Appendix}{}% 17
\BOOKMARK [2][-]{subsection.6.1}{Additional mathematical background}{section.6}% 18
\BOOKMARK [3][-]{subsubsection.6.1.1}{MMD in Reproducing Kernel Hilbert Spaces \(RKHS\)}{subsection.6.1}% 19
\BOOKMARK [3][-]{subsubsection.6.1.2}{Optimal transport}{subsection.6.1}% 20
\BOOKMARK [3][-]{subsubsection.6.1.3}{Stochastic processes}{subsection.6.1}% 21
\BOOKMARK [3][-]{subsubsection.6.1.4}{Additional lemmas}{subsection.6.1}% 22
\BOOKMARK [2][-]{subsection.6.2}{Proofs of sec:mmdflow}{section.6}% 23
\BOOKMARK [3][-]{subsubsection.6.2.1}{Proof of prop:mmdflow}{subsection.6.2}% 24
\BOOKMARK [3][-]{subsubsection.6.2.2}{Proof of prop:lambdaconvexity \(Displacement convexity\)}{subsection.6.2}% 25
\BOOKMARK [3][-]{subsubsection.6.2.3}{Proof of cor:integrallambdaconvexity}{subsection.6.2}% 26
\BOOKMARK [3][-]{subsubsection.6.2.4}{Proof of cor:loserbound}{subsection.6.2}% 27
\BOOKMARK [3][-]{subsubsection.6.2.5}{Proof of prop:almostconvexoptimization}{subsection.6.2}% 28
\BOOKMARK [2][-]{subsection.6.3}{Proofs of sec:discretizedflow}{section.6}% 29
\BOOKMARK [3][-]{subsubsection.6.3.1}{Proof of prop:decreasingfunctional}{subsection.6.3}% 30
\BOOKMARK [3][-]{subsubsection.6.3.2}{Proof of prop:evi}{subsection.6.3}% 31
\BOOKMARK [2][-]{subsection.6.4}{proof of prop:decreasinglossiterations}{section.6}% 32
\BOOKMARK [3][-]{subsubsection.6.4.1}{Proof of th:ratesmmd}{subsection.6.4}% 33
