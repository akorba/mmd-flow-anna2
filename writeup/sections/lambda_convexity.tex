%\section{Theoretical properties of the MMD flow}\label{sec:theory}



\subsection{Lambda displacement convexity of the MMD}\label{subsection:barrier_optimization}
One important criterion to characterize the convergence of the Wasserstein gradient flow of a functional $\F$ is the \textit{displacement convexity} of such a functional. Displacement convexity (see \cite{Villani:2004}, Definition 1) states that $t\mapsto \F(\rho_t)$ is a convex function whenever $t\mapsto\rho_t$ is a path of minimal length from two distributions $\mu$ and $\nu$ as explained formally in \cref{def:displacement_convexity}. The notion of path of minimal length depends on the choice of the metric. In the case of Wasserstein metric, such paths are called  \textit{displacement geodesics}, they are in general intractable to compute. Other distances would lead to different geodesics. For a more in-depth discussion we refer to \cite{Bottou:2017}.


%A noticeable example is when $\mathcal{P}_2(\X)$ is endowed with the MMD as a distance. In this case, the shortest paths are called \textit{mixture geodesics} and are of the form $\rho_t = (1-t)\mu + t\nu$.

%Convex functionals convex functionals are those  satisfying $\F(t\nu +(1-t)\nu')\leq t\F(\nu)+(1-t)\F(\nu')$.
This notion of convexity should not be confused with \textit{mixture convexity} which corresponds to the usual notion of convexity. As a matter of fact, $\F$ is \textit{mixture convex} in that it satisfies: $\F(t\nu +(1-t)\nu')\leq t\F(\nu)+(1-t)\F(\nu')$ for all $t\in [0,1]$ and for all $\nu,\nu'\in\mathcal{P}_2(\X)$ (\cref{lem:mixture_convexity}. Unfortunately, $\F$ is not \textit{displacement convex} which makes the gradient flow prone to converge to local minima. However, it can be shown that the flow of $\F$ can decrease until it reaches a barrier. The size of the barrier depends on a relaxed notion of convexity called $\Lambda$-displacement convexity:

%\begin{definition}\label{def:lambda-convexity}
%($\Lambda$-convexity \cite{Villani:2009} Definition 16.4). Let $(\nu,v)\mapsto\Lambda(\nu,v)$
%be a function that defines for each $\nu \in \mathcal{P}(\X)$
%a quadratic form on the set of square integrable vectors valued functions
%$v$ , i.e: $v\in L_{2}(\mathbb{R}^{d},\mathbb{R}^{d},\nu)$ . We
%further assume that $\inf_{\nu,v}\Lambda(\nu,v)/\Vert v\Vert_{L_{2}(\nu)}^{2}>-\infty$.
%%\[
%%\inf_{\nu,v}\frac{\Lambda(\nu,v)}{\Vert v\Vert_{L_{2}(\nu)}^{2}}>-\infty.
%%\]
%We say that a functional $\nu\mapsto\mathcal{F}(\nu)$ is $\Lambda$-convex
%if for any $\nu$ and $\nu'$ and a minimizing geodesic $\text{\ensuremath{\rho_{t}}}$
%between $\nu$ and $\nu'$ with velocity vector field $v_{t}$, i.e:
%$\partial_{t}\rho_{t}+div(\rho_{t}v_{t})=0;\rho_{0}=\nu;\rho_{1}=\nu';$
%the following holds:
%\begin{equation*}
%F(\rho_{t})\leq (1-t)\F(\nu)+t\F(\nu') -\int_0^1 \Lambda(\rho_{t},v_{t})\qquad\forall\; t\in[0,1].
%\end{equation*}
%\end{definition}
%
%
%It can be shown that $\F$ is $\text{\ensuremath{\Lambda}}$-displacement convex under mild assumptions on the kernel $k$:
%\begin{proposition}
%\label{prop:lambda_convexity} Suppose \cref{assump:bounded_fourth_oder} is satisfied for some $\lambda \in \R^+$. Then $\F$ is $\text{\ensuremath{\Lambda}}$-displacement convex with $  \Lambda(\rho,v) = -\lambda \mathcal{\rho}^{\frac{1}{2}} \int \Vert v(x) \Vert^2 \diff\rho(x)$.
%Moreover, for any displacement geodesic $\rho_t$ between two distributions $\nu$ and $\nu'$ it holds 
%\begin{align}
%	\bar{\F}(\rho_t) \geq -\lambda \F{\rho_t}^{\frac{1}{2}} W_2^2(\nu,\nu')
%\end{align}
%\end{proposition}
%
%
%
%
%
%
%
%
%
%
%
%
%\begin{definition}\label{def:displacement_convexity}
% Let $\mu$
%and $\nu$ in $\mathcal{P}(\X)$. There exists a $\mu-a.e.$
%unique gradient of a convex function, denoted by $\nabla\phi$, such that $\mu$
%is equal to $\nabla\phi_{\#}\nu$ and one can define \aknote{the displacement geodesic?} $\rho_{t}=((1-t)Id+t\nabla\phi)_{\#}\nu$
%for $0\leq t\leq1$. We say that a functional $\nu\mapsto\mathcal{F}(\nu)$
%is displacement convex if 
%\begin{equation}
%t\mapsto\mathcal{F}(\rho_{t})
%\end{equation}
% is convex for any $\nu$ and $\mu$. Moreover, we say that $\mathcal{F}$
%is displacement convex in a neighborhood of $\mu$ if there exists a radius $r>0$
%such that the above property holds for any $\nu$ with $W_{2}(\mu,\nu)\leq r$.
%\end{definition}


%This notion of convexity is to be related to the more widely used notion of convexity called \textit{mixture convexity}:
%\begin{align}
%	\F(t\nu +(1-t)\nu')\leq t\F(\nu)+(1-t)\F(\nu') \qquad t\in [0,1]
%\end{align}
%%Unlike mixture convexity, displacement convexity is compatible with the $W_2$ metric and is therefore the natural notion to use for characterizing convergence of gradient flows in the $W_2$ metric.
%Although mixture convexity holds for $\F$ (see \cref{lem:mixture_convexity}), this property is less critical for characterizing convergence of gradient flows in the $W_2$ metric. On the other hand, displacement convexity is compatible with the $W_2$ metric \cite{Bottou:2017} and is therefore the natural notion to use in our setting. Unfortunately, $\F$ fails to be displacement convex in general. Instead we will show that $\F$ satisfies some weaker notion of convexity called $\Lambda$-displacement convexity:
%
\begin{definition}\label{def:lambda-convexity}
($\Lambda$-convexity \cite{Villani:2009} Definition 16.4). Let $(\nu,v)\mapsto\Lambda(\nu,v)$
be a function that defines for each $\nu \in \mathcal{P}(\X)$
a quadratic form on the set of square integrable vectors valued functions
$v$ , i.e: $v\in L_{2}(\mathbb{R}^{d},\mathbb{R}^{d},\nu)$ . We
further assume that $\inf_{\nu,v}\Lambda(\nu,v)/\Vert v\Vert_{L_{2}(\nu)}^{2}>-\infty$.
%\[
%\inf_{\nu,v}\frac{\Lambda(\nu,v)}{\Vert v\Vert_{L_{2}(\nu)}^{2}}>-\infty.
%\]
We say that a functional $\nu\mapsto\mathcal{F}(\nu)$ is $\Lambda$-convex
if for any $\nu$ and $\mu$ and a minimizing geodesic $\text{\ensuremath{\rho_{t}}}$
between $\nu$ and $\mu$ with velocity vector field $v_{t}$, i.e:
$\partial_{t}\rho_{t}+div(\rho_{t}v_{t})=0;\rho_{0}=\nu;\rho_{1}=\mu;$
the following holds:
\begin{equation*}
\frac{d^{2}\mathcal{F}(\rho_{t})}{dt^{2}}\geq\Lambda(\rho_{t},v_{t})\qquad\forall\; t\in[0,1].
\end{equation*}
\end{definition}

To show the $\Lambda$-convexity of the functional defined in \cref{eq:mmd_functional} we first make the following assumptions on the kernel:
\begin{assumplist} 
\item \label{assump:bounded_trace} $ \vert \sum_{1\leq i\leq d} \partial_i\partial_ik(x,x) \vert\leq \frac{L}{3}  $ for all $x\in \mathbb{R}^d$.
\item \label{assump:bounded_hessian} $\Vert H_xk(x,y) \Vert_{op} \leq \frac{L}{3}$ for all $x,y\in \mathbb{R}^d$, where $H_xk(x,y)$ is the hessian of $x\mapsto k(x,y)$ and $\Vert.\Vert_{op}$ is the operator norm.
\item \label{assump:bounded_fourth_oder} $\Vert Dk(x,y) \Vert\leq \lambda  $ for all $x,y\in \mathbb{R}$, where $Dk(x,y)$ is an $\mathbb{R}^{d^2}\times \mathbb{R}^{d^2}$ matrix with entries given by $\partial_{x_{i}}\partial_{x_{j}}\partial_{x'_{i}}\partial_{x_{j}'}k(x,x')$.
\end{assumplist}\aknote{do we have an order of magnitude for lambda? or just we put a remark to say it's satisfied by the gaussian kernel}
The next proposition states that the functional defined in \cref{eq:mmd_functional} is $\Lambda$-displacement convex and provide and explicit expression for the functional $\Lambda$.

\begin{proposition}
\label{prop:lambda_convexity} Suppose \cref{assump:bounded_fourth_oder} is satisfied for some $\lambda \in \R^+$. The functional $\nu\mapsto \F(\nu)$ is $\text{\ensuremath{\Lambda}}$-convex
with $\Lambda$ given by:
\begin{equation}
\Lambda(\nu,v)=\langle v,(C_{\nu}-\lambda \F(\nu)^{\frac{1}{2}}I)v\rangle_{L_{2}(\nu)}\label{eq:Lambda}
\end{equation}
where $C_{\nu}$ is the (positive) operator defined by:
\begin{align}\label{eq:positive_operator_C}
	(C_{\nu}v)(x)=\int\nabla_{x}\nabla_{x'}k(x,x')v(x')d\nu(x')
\end{align}
\end{proposition}
%
%
Consider the geodesic $\rho_{t}=((1-t)Id+t\nabla\phi)_{\#}\nu$ of \cref{def:displacement_convexity}. It is worth noting that $\rho_{1}=\mu$ and at time $t=1$ we have
that $\F(\rho_{1})=0$, hence we get:
\[
\frac{d^{2}\F(\rho_{t})}{dt^{2}}\vert_{t=1}=\langle v_{t},C_{\rho_{t}}v_{t}\rangle_{L_{2}(\rho_{t})}\geq0.
\]
This shows that $\nu\mapsto \F(\nu)$ has a non-negative
hessian at $\mu$ which is not surprising since $\mu$ is the global
minimum of this functional.
\begin{corollary}\label{cor:integral_lambda_convexity}\aknote{we can merge the two corollaries}
For any geodesic $\rho_{t}$ between
$\rho_{0}$ and $\rho_{1}$ in $\mathcal{P}(\X)$ the following holds:
\begin{equation}
\F(\rho_{t})\leq(1-t)\F(\rho_{0})+t\F(\rho_{1})-\int_{0}^{1}\Lambda(\rho_{s},v_{s})G(s,t)ds\label{eq:integral_lambda_convexity}
\end{equation}
where $\Lambda$ is given by \cref{eq:Lambda} and $G(s,t)=s(1-t) \mathbb{I}\{s\leq t\}
+t(1-s) \mathbb{I}\{s\geq t\}$.
%and $G$ is given
%by:
%\[
%G(s,t)=\begin{cases}
%s(1-t) & s\leq t\\
%t(1-s) & s\geq t
%\end{cases}
%\]
\end{corollary}
%

\begin{corollary}
\label{cor:loser_bound}Assume the distributions are supported on
$\mathcal{X}$ and the kernel is bounded, i.e: $\sup_{x,y\in\mathcal{X}}\vert k(x,y)\vert<\infty$.
Then the following holds:
\begin{equation}
\F(\rho_{t})\leq(1-t)\F(\rho_{0})+t\F(\rho_{1})+t(1-t)K
\end{equation}
where $K$ is a constant depending on $\X$ and the kernel $k$ in $\F$.
\end{corollary}
%
%
\cref{cor:loser_bound}, is a loser bound and does not account for the local
convexity of the MMD. However, it allows to state the following result,
which is inspired from (\cite{Bottou:2017}, Theorem 6.3) but generalizes
it to the case of 'almost convex' functionals.
\begin{proposition}
\label{prop:almost_convex_optimization}
(Almost convex optimization). Let $\mathcal{P}$ be a closed subset
of $\mathcal{P}(\mathcal{X})$ which is displacement convex\aknote{weird for a set to be displacement convex? it was for functionals}. Then
for all $M>\inf_{\rho\in\mathcal{P}}\F(\rho)+K$, the following
holds:
\end{proposition}
\begin{enumerate}
\item The level set $L(\mathcal{P},M)=\{\rho\in\mathcal{P}:\F(\rho)\leq M\}$
is connected
\item For all $\rho_{0}\in\mathcal{P}$ such that $\F(\rho_0)>M$
and all $\epsilon>0$, there exists $\rho\in\mathcal{P}$ such that
$W_{2}(\rho,\rho_{0})=\mathcal{O}(\epsilon)$ and
\[
\F(\rho)\leq \F(\rho_{0})-\epsilon(\F(\rho_{0})-M).
\]
\end{enumerate}
%
%\begin{remark}
The result in \Cref{prop:almost_convex_optimization} means that it is possible to optimize the cost function $\rho\mapsto \F(\rho)$
on $\mathcal{P}$ as long as the barrier $\inf_{\rho\in\mathcal{P}}\F(\rho)+K$
is not reached. A possible direction would be to directly leverage the tighter inequality in \cref{eq:integral_lambda_convexity} to get a better description of the loss landscape.%We provide now a simple proof of this result.
%\end{remark}

\cref{prop:almost_convex_optimization} guarantees the existence of a direction of descent that minimizes the functional $\F$ provided that the starting point $\rho_1$ has a potential greater than the barrier $K$.%, i.e:
%\begin{align}\label{eq:barrier_condition}
%	\F(\rho_1)> \inf_{\rho\in \mathcal{P}} \F(\rho) + K
%\end{align}
One natural question to ask is whether the  discretized gradient flow algorithm provides such way to reach the barrier $K$ and at what speed this happens. This subsection will answer that question. Firstly, we state few propositions that will lead us to the final result.


%\begin{proposition}\label{prop:decreasing_functional}
%	Under \cref{assump:bounded_trace,assump:bounded_hessian}, the following inequality holds:
%	\begin{align*}
%	\F(\nu_{n+1})-\F(\nu_n)\leq -\gamma (1-\frac{\gamma}{2}L )\int \Vert \phi_n(X)\Vert^2 d\nu_n
%	\end{align*}
%\end{proposition}

\begin{proposition}\label{prop:evi}
	Consider the sequence of distributions $\nu_m$ obtained from \cref{eq:discretized_flow}. If $\gamma \leq 1/L$, then
	\begin{align}
2\gamma(\F(\nu_{m+1})-\F(\mu))
\leq 
W_2^2(\nu_m,\mu)-W_2^2(\nu_{m+1},\mu)-2\gamma K(\rho^m).
\label{eq:evi}
\end{align}
where $(\rho^m_t)_{0\leq t \leq 1}$ is a constant-speed geodesic from $\nu_n$ to $\mu$ and $K(\rho^m):=\int_0^1 \Lambda(\rho^m_s,\dot{\rho^m}_s)(1-s)ds$.
\end{proposition}

\begin{theorem}\label{th:rates_mmd}
	Consider the sequence of distributions $\nu_n$ obtained from \cref{eq:discretized_flow}. If $\gamma \leq 1/L$, then
	%\begin{align}
%\F(\bar{\nu}_{n})-\F(\mu)\leq  \frac{W_2^2(\nu_0,\mu)}{2 \gamma n} -\bar{K}
%\end{align}
%where $\bar{\nu}=\frac{1}{N}\sum_{n=1}^N \nu_n$. Moreover, 
\begin{align}
\F(\nu_m)-\F(\mu)\leq  \frac{W_2^2(\nu_0,\mu)}{2 \gamma m} -\bar{K}.
\end{align}
\end{theorem}





%\begin{remark}
%	A possible direction would be to directly leverage the tighter inequality in \cref{eq:integral_lambda_convexity} to get a better description of the loss landscape.
%\end{remark}





