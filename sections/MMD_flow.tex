\section{Theoretical properties of the MMD gradient flow}\label{sec:mmd_flow}

\subsection{MMD gradient flow}

We will consider a flow $(\rho_t)_{t>0}$ as described in \cref{sec:gradient_flows_functionals} and denote $f_t= \int k(.,z)\diff \mu - \int k(.,z)\diff \rho_t$. In this case:
\begin{equation}
\F(\rho_t)=\frac{1}{2}\|f_t\|^2_{\kH}
%&= \E_{\rho_t \otimes \rho_t}[k(X,X')]+\E_{\pi \otimes \pi}[k(Y,Y')] - 2\E_{\rho_t \otimes \pi}[k(X,Y)]
\end{equation} 

We define the potential energy (also called confinement energy) $V$ and interaction energy $W$ as follows:
\begin{equation}
V(x)=-\int  k(x,x')\mu(x')\text{,} \quad
W(x,x')=\frac{1}{2}k(x,x')
\end{equation}
We have $1/2MMD^2(\rho,\mu)=C+ \int V(x) \rho(x)dx + \int W(x,x')\rho(x)\rho(x')$, where $C=1/2\E_{\mu\otimes \mu}[k(x,x')]$. $MMD^2$ can thus be written as a \textit{Lyapunov functional} (or "free energy" or "entropy") $\F$ as in \eqref{eq:lyapunov}.



\begin{proposition}\label{prop:mmd_flow}
 The velocity in \eqref{eq:continuity_equation1} is given by $\nabla \frac{\partial{\F}}{\partial{\rho_t}}=\nabla f_t$ and the dissipation of MMD can be written:  
	\begin{equation}
	\frac{d MMD^2(\rho_t, \mu)}{dt}=-\E_{X \sim \rho_t}[\|\nabla f_t(X)\|^2]
	\end{equation}
	where $\nabla f_t(z)= \int \nabla_{z}k(.,z) d\mu -  \int \nabla_{z}k(.,z) d\rho_t$.
\end{proposition}

\begin{remark}
	If the functional $\F$ was the KL divergence and $\rho_t$ a weak solution of Equation\eqref{eq:Fokker-Planck}, we would obtain the following dissipation (see \cite{wibisono2018sampling}):
	\begin{equation}
	\frac{d KL(\rho_t, \mu)}{dt}=-\E_{X \sim \rho_t}[\|\nabla log(\frac{\rho_t}{\mu}(X))\|^2]
	\end{equation}
\end{remark}


As explained in \cref{sec:gradient_flows_functionals} and according to \cref{prop:mmd_flow}, the gradient flow of the MMD can be written:
\begin{equation}\label{eq:continuity_equation_mmd}
\frac{\partial \rho_t}{\partial t}= div(\rho_t  \nabla f_t)
\end{equation}
The stochastic process whose distribution satisfies \eqref{eq:continuity_equation_mmd} can thus be written (see \cref{sec:ito_stochastic}):
\begin{equation}\label{eq:stochastic_process}
dX_t=-\nabla f_t(X_t) = - (\nabla V (X_t) + \nabla W * \rho_t(X_t))
\end{equation}
Equation \eqref{eq:stochastic_process}, which can be interpreted as the position $X_t$ of a particle at time $t > 0$, can be written as a Mac-Kean Vlasov model (see \cite{kac1956foundations}, \cite{mckean1966class}), a particular kind of SDE driven by a Levy process:
\begin{align}\label{eq:theoretical_process}
&X_t=X_{0}+\int_{0}^t \sigma(X_s, \rho_s, \mu)ds \quad \text{for t in [0,T]}\\
&\forall s \in [0,T]\;,\quad \rho_s \text{ denotes the probability distribution of } X_s
\end{align}
with $\sigma(X_s, \rho_s, \mu)=-\nabla f_t(X_s)=\int \nabla_{X_s}k(.,X_s) d\rho_t -  \int \nabla_{X_s}k(.,X_s) d\mu$. Suppose that $k$ is bounded\aknote{as well as $\nabla_k$?} and measurable on $\X$, and that there exists $L_k$ such that $\forall x,y \in \X$, $\| k(x,.)-k(y,.) \|_{\kH}\le L_k \|x-y\|$. Hence, $\sigma$ is bounded and Lipschitz continuous in its first variable (if the kernel is itself Lipschitz), and linear in its second and third variable. 
\aknote{investigate conditions on the kernel for convergence, uniqueness. e.g. linear growth of the coefficient sigma? or does it relate to lambda convexity as santambrogio says? or Following Chizat Bach [CB18b] solutions exist for all t > 0 for appropriate initial $\mu_0$ that are compactly
	supported in $\X$?}


\begin{remark}
	Consider a family of particles such that its density satisfy Equation\eqref{eq:continuity_equation}. Both KL and MMD have a non-zero potential energy $V$ which drive these particles to the target distribution $\mu$. While he entropy function $U$ in KL prevents the particle from "crashing" onto the mode of $\mu$, this role could be played by the interaction energy $W$ for MMD. Indeed, when $W$ is convex, this gives raise to a general
	aggregation behavior of the particles, while when it is not, the particles would push each other apart.\aknote{to check, ref malrieu?}
\end{remark}

\begin{remark}
	We point out here that algorithm~\eqref{eq:sample_based_process} is different from the descent proposed by \cite{mroueh2018regularized}. 
\end{remark}


\input{sections/lambda_convexity}

\input{sections/lojasiewicz}

%\subsection{MMD flows in the literature}


