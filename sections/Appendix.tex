

\section{Appendix}\label{sec:appendix}

\subsection{Additional mathematical background}
%In all what follows, $\X$ is a convex subset of $\R^d$ and $\mathcal{P}_2(\X)$ denotes the set of all probability distributions supported on $\X$ with finite second moment.
%For a given distributions $\nu\in\mathcal{P}_2(\X)$ and an integrable function $f$ under $\nu$, the expectation of $f$ under $\nu$ will be written either as $\nu(f)$ or $\int f \diff\nu$ depending on the context. 



\subsubsection{Stochastic processes}\label{sec:ito_stochastic}

Consider the Itô process, i.e. the stochastic process:
\begin{equation}
dX_t=g(X_t)dt.
\end{equation}
Let $f$ be a twice-differentiable scalar function, Itô's formula (see \cite{ito1951stochastic}) can be written:
\begin{equation}
df(X_t)=\nabla f(X_t).g(X_t)dt
\end{equation}
Let $\rho_t$ be the distribution of the process $X_t$. We have:
\begin{align}
\E[\frac{df}{dt}(X_t)]&= \E[\nabla f(X_t).g(X_t)]\\
\Longleftrightarrow \int f(X) \frac{d \rho_t}{dt}(X)&=-\int f(X)div(g(X)\rho_t(X))
\end{align}
where the second line is obtained by integrating by parts on both sides of the equality. Finally, the distribution $\rho_t$ verifies the continuity equation: 
\begin{equation}
\frac{d\rho_t}{dt}=div(g\rho_t)
\end{equation}


\begin{lemma}\label{lem:mmd_w2}
	 Suppose that $k$ is bounded and measurable on $\X$, and that there exists $L_k$ such that $\forall x,y \in \X$, $\| k(x,.)-k(y,.) \|_{\kH}\le L_k \|x-y\|$. Then for all $\mu, \nu$ in $\mathcal{P}(\X)$:
	\begin{equation}
	MMD^2(\mu,\nu)\le  L_k W_1^2(\mu,\nu) \le L_k W_2^2(\mu,\nu)
	\end{equation}
\end{lemma}
\begin{proof}
Let $\mu, \nu$ in $\mathcal{P}(\X)$. By Proposition 20 in \cite{sriperumbudur2010hilbert} we have:
\begin{equation}
	MMD(\mu, \nu)	 \le \inf_{\pi \in \Pi(\mu, \nu)} \int \| k(x,.)-k(y,.) \|_{\kH} d\pi(\mu, \nu)
\end{equation}

Hence:
\begin{align}
	MMD^2(\mu, \nu)	
	 \le (\inf_{\pi \in \Pi(\mu, \nu)} \int L_k \| x-y \| d\pi(\mu, \nu))^2
 \le L_k^2 W_1^2(\mu, \nu) \le L_k^2 W_2^2(\mu,\nu)
\end{align}
\end{proof}

\subsection{Proofs}

\subsubsection{Proof of \cref{prop:mmd_flow}}

In the case where $\F= \frac{1}{2} \|f_t\|^2_{\kH}$, by simple derivations we obtain:
\begin{equation}
 \nabla \frac{\partial\frac{1}{2} \|f_t\|^2_{\kH}}{\partial \rho_t}= \nabla \langle \frac{\partial f_t}{\partial \rho_t}, f_t \rangle_{\kH}= \nabla \langle \frac{\partial \E_{\rho_t}[k(Y,.)]}{\partial \rho_t}, f_t \rangle_{\kH}= \nabla \langle k(Y,.), f_t \rangle_{\kH}
\end{equation}
Then, by applying the reproducing property we have that:
\begin{equation}
\nabla \langle k(Y,.), f_t \rangle_{\kH}
= \nabla f_t(Y)
\end{equation}
where $\nabla f_t(Y)= \E_{X \sim \rho_t}[\nabla_{Y}k(X,Y)] -  \E_{X \sim \pi}[\nabla_{Y}k(X,Y)]$.

\subsubsection{Proof of \cref{prop:lambda_convexity} (Displacement convexity)}

We will firstly need the following lemma.

\begin{lemma}\label{lem:derivatives_witness}
	Let  $\mu$, $\nu_0$ and $\nu_1$ be three distributions in $\mathcal{P}_2(\X)$ and consider a displacement geodesic $(\rho_t)_{t\in[0,1]}$ between $\nu_0$ and $\nu_1$  defined by \cref{eq:displacement_geodesic} 
	and its corresponding velocity vector $(v_t)_{t\in [0,1]}$ as defined in \cref{eq:continuity_equation}. The following statements hold:
	\begin{enumerate}
		\item The first and second time derivatives of the witness function $f_{\mu,\rho_t}$ between $\mu$ and $\rho_t$ are well defined elements in $ \kH$ and are given by:
		\begin{align}\label{eq:derivatives_witness}
		\dot{f}_{\mu,\rho_t} = \int \nabla_1 k(x,.).v_t(x) \diff \rho_t(x); \qquad
		\ddot{f}_{\mu,\rho_t} = \int v_t(x)^T\nabla_1^2 k(x,.).v_t(x) \diff \rho_t(x)
		\end{align}
		where $ x \mapsto \nabla_1 k(x,z)$ and $x\mapsto \nabla_1^2 k(x,z)$ respectively denote the gradient and hessian of $x\mapsto k(x,z)$ for a fixed $z$ in $\X$.
		\item For all $g\in \kH$:
		\begin{align}\label{eq:inner_prod_deriative_witness}
		\langle g,\dot{f}_{\mu,\rho_t}\rangle_{\kH} = \int \nabla_1 g.v_t \diff \rho_t; \qquad
		\langle g,  \ddot{f}_{\mu,\rho_t}\rangle_{\kH} = \int v_t^T\nabla_1^2 g.v_t \diff \rho_t
		\end{align}
		\item The RKHS norms of $\dot{f}_{\mu,\rho_t}$ and $\ddot{f}_{\mu,\rho_t}$ satisfy:
		\begin{align}\label{eq:norm_derivative_witness}
		\Vert \dot{f}_{\mu,\rho_t}\Vert_{\kH}^2 = \langle v_t,C_{\rho_t} v_t \rangle_{L_2(\rho_t)}; \qquad  \Vert \ddot{f}_{\mu,\rho_t} \Vert\leq \lambda \Vert v_t \Vert^2_{L_2(\rho_t)}  
		\end{align}
		with $\lambda$ given by \cref{assump:bounded_fourth_oder} and $C_{\nu}$ defined in \cref{prop:lambda_convexity}. 
	\end{enumerate} 
\end{lemma}
\begin{proof}
	By definition of $\rho_{t}$:
	\[
	f_t(z)= \int k(x,z)\diff \mu(x) - \int k(s_t(x,y),z)\diff \pi(x,y)
	\]
	\manote{proof}
\end{proof}


\begin{proof}
To prove that $\nu\mapsto \F(\nu)$ is $\Lambda$-convex
we need to compute the second derivative $\ddot{\F}(\rho_{t})$
where $\rho_{t}$ is a displacement geodesic between two probability
distributions $\nu_{0}$ and $\nu_{1}$ as defined in \cref{eq:displacement_geodesic}. Such a minimizing geodesic always exists and can be written as $\rho_t = (s_t)_{\#}\pi$ with $s_t$ defined in \cref{eq:convex_combination} and $\pi$ is an optimal coupling between $\nu_0$ and $\nu_1$ (\cite{Santambrogio:2015}, Theorem 5.27). Moreover, we denote by $v_t$ the corresponding velocity vector as defined in \cref{eq:continuity_equation}. Recall from \cref{eq:mmd_norm_witness} that $\F(\rho_t) = \frac{1}{2} \Vert f_{\mu,\rho_t}\Vert^2_{\mathcal{H}}$, with $f_{\mu,\rho_t}$ defined in \cref{eq:witness_function}. To simplify notations we will write $f_t:= f_{\mu,\rho_t}$. We start by computing the first derivative of $ t\mapsto \F(\rho_t) $. By  \cref{lem:derivatives_witness},\cref{eq:derivatives_witness}, we know that $\dot{f}_t$ and $\ddot{f}_t $ are well defined elements of $\kH$ for any given $t\in [0,1]$, hence 
\[
 \dot{\F}(\rho_t) = \langle f_t, \dot{f_t}\rangle_{\kH};\qquad \ddot{\F}(\rho_t) = \Vert \dot{f_t}\Vert^2_{\kH} + \langle f_t, \ddot{f_t}\rangle_{\kH}.
 \]
While $\Vert \dot{f_t}\Vert^2_{\kH}$ is non-negative, $\langle f_t, \ddot{f_t}\rangle_{\kH}$ can in general be negative. We are only interested in quantifying how negative it can get, for this purpose we use Cauchy-Schwartz inequality which directly gives:
\[
\ddot{\F}(\rho_t)\geq  \Vert \dot{f}_t \Vert^2_{\kH} - \Vert f_t \Vert_{\kH}\Vert \ddot{f}_t\Vert_{\kH} 
\]

Finally by \cref{lem:derivatives_witness}, \cref{eq:norm_derivative_witness}, we can conclude that:
\[
	\ddot{\F}(\rho_t)\geq  \langle v_t,(C_{\rho_t} - \lambda \F(\rho_t)^{\frac{1}{2}}) v_t \rangle_{L_2(\rho_t)} 
\]
with $C_{\rho_t}$ given by \cref{eq:positive_operator_C} and $I$ is the identity operator in $L_2(\rho_t)$. Now we can introduce the function:
\begin{align}
	\Lambda(\nu,v) = \langle v ,( C_{\nu} -\lambda \F(\nu)^{\frac{1}{2}} I) v \rangle_{L_2(\nu)} 
\end{align}
which is defined for any pair $(\nu,v)$ with  $\nu\in \mathcal{P}_2(\X)$ and $v$ a square integrable vector field in $L_2(\nu)$. It is clear that $\Lambda(\nu,.)$  is a quadratic form on $L_2(\nu)$. Therefore, from \cref{def:lambda-convexity} of $\Lambda$ convexity, we conclude that $\F$ is $\Lambda$-convex.
\end{proof}

%
%
%
%By \cref{lem:derivatives_witness}, we have that $\dot{f_t}\in \kH$ and 
%
% it follows from \manote{some assumption to exchange orders}
%\[
%\frac{df_{t}}{dt}=\int(\nabla\phi(x)-x).\nabla k(\pi_{t}(x),.)\nu_{0}(x)dx
%\]
%hence:
%\[
%\frac{dMMD^{2}(\mu,\rho_{t})}{dt}=2\int(\nabla\phi(x)-x).\nabla f_{t}(\pi_{t}(x))\nu_{0}(x)dx
%\]
%Now the second derivative is given by:
%\begin{align*}
%\frac{d^{2}MMD^{2}(\mu,\rho_{t})}{dt^{2}}= & \int(\nabla\phi(x)-x).Hf_{t}(\pi_{t}(x))(\nabla\phi(x)-x)\nu_{0}(x)dx\\
% & +\int(\nabla\phi(x)-x).\nabla_{1}\nabla_{2}k(\pi_{t}(x),\pi_{t}(x'))(\nabla\phi(x')-x')\nu_{0}(x)\nu_{0}(x')dxdx'
%\end{align*}
%Here $\nabla_{1}\nabla_{2}k(x,x')$ is the matrix whose components
%are given by $\langle\partial_{i}k(x,.),\partial_{j}k(x,.)\rangle$
%for $1\leq i,j\leq d$, and $Hf_{t}$ is the hesssian of $f_{t}$
%and its components are also given by:
%\[
%(Hf_{t}(x))_{i,j}=\langle f_{t},\partial_{i}\partial_{j}k(x,.)\rangle.
%\]
%Denoting by $h(x):=\nabla\phi(x)-x$ it follows that:
%\begin{align*}
%\frac{d^{2}MMD^{2}(\mu,\rho_{t})}{dt^{2}}= & \langle f_{t},\int\sum_{i,j}h_{i}(x)h_{j}(x)\partial_{i}\partial_{j}k(\pi_{t}(x),.)\nu_{0}(x)dx\rangle\\
% & +\Vert\int\sum_{i}h_{i}(x)\partial_{i}k(\pi_{t}(x),.)\nu_{0}(x)dx\Vert^{2}
%\end{align*}
%Now we use Cauchy-Schwartz inequality for the first term to get:
%\begin{align*}
%\frac{d^{2}MMD^{2}(\mu,\rho_{t})}{dt^{2}}\geq & -\Vert f_{t}\Vert_{\kH}\Vert\int\sum_{i,j}h_{i}(x)h_{j}(x)\partial_{i}\partial_{j}k(\pi_{t}(x),.)\nu_{0}(x)dx\Vert_{\kH}\\
% & +\Vert\int\sum_{i}h_{i}(x)\partial_{i}k(\pi_{t}(x),.)\nu_{0}(x)dx\Vert^{2}.
%\end{align*}
%After applying a change of variables $x=\pi_{t}(y)$ one recovers the
%velocity vector $v_{t}$ instead of $h$: 
%\begin{align*}
%\frac{d^{2}MMD^{2}(\mu,\rho_{t})}{dt^{2}}\geq & -\Vert f_{t}\Vert_{\kH}\Vert\int\sum_{i,j}v_{t}^{i}(x)v_{t}^{j}(x)\partial_{i}\partial_{j}k(x,.)\rho_{t}(x)dx\Vert_{\kH}\\
% & +\Vert\int\sum_{i}v_{t}^{i}(x)\partial_{i}k(x,.)\rho_{t}(x)dx\Vert^{2}.
%\end{align*}
%
%One can further note that:
%\[
%\Vert\int\sum_{i,j}v_{t}^{i}(x)v_{t}^{j}(x)\partial_{i}\partial_{j}k(x,.)\rho_{t}(x)dx\Vert_{\kH}\leq\lambda\Vert v_{t}\Vert_{L_{2}(\rho_{t})}^{2}
%\]
%
%and that 
%\begin{align*}
%\Vert\int\sum_{i}v_{t}^{i}(x)\partial_{i}k(x,.)\rho_{t}(x)dx\Vert^{2} & =\int v_{t}(x)^{T}\int\nabla_{1}\nabla_{2}k(x,x')v_{t}(x')\rho_{t}(x')dx'dx.\\
% & =\langle v_{t},C_{\rho_{t}}v_{t}\rangle_{L_{2}(\rho_{t})}
%\end{align*}
%
%Hence we have shown that 
%\[
%\frac{d^{2}MMD^{2}(\mu,\rho_{t})}{dt^{2}}\geq\langle v_{t},(C_{\rho_{t}}-\lambda MMD(\mu,\rho_{t})I)v_{t}\rangle_{L_{2}(\rho_{t})}=\Lambda(\rho_{t},v_{t})
%\]


\subsubsection{Proof of \cref{th:rates_mmd}}

\begin{lemma}	\label{lem:grad_flow_lambda_version}
Let $\nu$ be a distribution in $\mathcal{P}_2(\X)$ and $\mu$ the target distribution such that $\F(\mu)=0$.  Let $\pi$ be an optimal coupling between $\nu$ and $\mu$, and $\rho_t$ the displacement geodesic defined by \cref{eq:displacement_geodesic} with its corresponding velocity vector  $v_t$ as defined in \cref{eq:continuity_equation}. Finally let $\phi(X)=\nabla f_{\nu,\mu}(X)$ the gradient of the witness function between $\mu$ and $\nu$. The following inequality holds: \manote{This should be a standard result, just need to cite it}
\begin{align*}
	\int \phi(x).(y-x) d\pi(x,y)
	\leq
	\F(\mu)- \F(\nu) -\int_0^1 \Lambda(\rho_s,v_s)(1-s)ds
\end{align*}

\end{lemma}
\begin{proof}
Recall that $\rho_t$ is given by $\rho_t = (s_t)_{\#}\pi$. By $\Lambda$-convexity of $\mathcal{F}$ the following inequality holds:
	\begin{align*}
		\mathcal{F}(\rho_{t})\leq (1-t)\mathcal{F}(\nu)+t \mathcal{F}(\mu) - \int_0^1 \Lambda(\rho_s,v_s)G(s,t)ds
	\end{align*}
	Hence by bringing $\mathcal{F}(\nu)$ to the l.h.s and dividing by $t$ and then taking its limit at $0$ it follows that:
	\begin{align*}
	\dot{\F}(\rho_t)\vert_{t=0}\leq \mathcal	{F}(\mu)-\mathcal{F}(\nu)-\int_0^1 \Lambda(\rho_s,v_s)(1-s)ds.	
	\end{align*}
	Moreover, by \cref{lem:derivatives_witness}, the time derivative of the witness function between $\nu$ and $\mu$ is well defined, so that $\dot{\F}(\rho_t)$ can be written as:
	\[
	\dot{\F}(\rho_t) = \langle f_{\mu,\rho_t},\dot{f}_{\mu,\rho_t} \rangle_{\kH}
	\]
	Now by \cref{lem:derivatives_witness},\cref{eq:inner_prod_deriative_witness} it follows that:
\[
\dot{\F}(\rho_t) = \int \nabla f_{\mu,\rho_t}(x).v_t(x)\diff \rho_t(x)
\]
By definition of $\rho_t$,  one can further write:
\[
\dot{\F}(\rho_t) = \int \nabla f_{\mu,\rho_t}(s_t(x,y)).(y-x)\diff \pi(x,y)
\]
where we used the fact that $v_t(s_t(x,y))=(y-x)$\manote{cite something}. Hence at $t=0$ we get:
\[
\dot{\F}(\rho_t)\vert_{t=0} = \int \nabla f_{\mu,\nu}(x).(y-x)\diff \pi(x,y)
\]
which shows the desired result.
\end{proof}





\begin{lemma}\label{lem:derivative_mmd}\manote{Notations still needs to be adjusted in this lemma}
	Let $\phi$ be a vector field on $\X$ and $\nu$ in $\mathcal{P}_2(\X)$. Consider the path $\delta_t$ between $\nu$ and $(I+\phi)_{\#}\nu$ given by:
	\begin{align*}
		\delta_t=  (I+t\phi)_{\#}\nu \qquad \forall t\in [0,1]
	\end{align*}
The time derivative of $\mathcal{F}(\delta_t)$ is given by:
	\begin{align*}
		\dot{\F}(\delta_t)&=\int \nabla f_{\mu,\delta_t}(x+t\phi(x)) \phi(x)d\nu(x)\\
	\end{align*}
where $f_{\mu,\delta_t}$ is the witness function between $\mu$ and $\delta_t$ as defined in \cref{eq:witness_function}.	
	Moreover, under \cref{assump:bounded_trace,assump:bounded_hessian}, the second time derivative satisfies:
	\begin{align*}
		\ddot{\F}(\delta_t) \vert \leq 3L \int \Vert \phi(x) \Vert^2 d\nu(x)
	\end{align*}
	where $L$ is a positive constant defined in \cref{assump:bounded_trace,assump:bounded_hessian}.
	
\end{lemma}
\begin{proof}
For simplicity, we write $f_t$ instead of $f_{\mu,\delta_t}$.
We start by computing the first derivative. Recalling that $\mathcal{F}(\delta_t)$ is given by $\frac{1}{2}\Vert f_t\Vert^2_{\kH} $, it follows that:
\[
\dot{\F}(\delta_t)=\langle f_{t},\frac{df_{t}}{dt}\rangle_{\kH}.
\]
Using the definition
of $\delta_{t}=(I+t\phi)_{\#}\nu$ we can write:\aknote{$\pi_t$? guess this corresponds to the paragraph below}
\[
\frac{df_{t}}{dt}=\int \phi(X).\nabla k(\pi_{t}(X),.)d\nu(X),
\]
hence:
\[
\frac{d\mathcal{F}(\delta_{t})}{dt}=2\int\phi(X).\nabla f_{t}(\pi_{t}(X))d\nu(X)
\]
Now the second derivative is obtained by direct derivation of the above expression:
	\begin{align*}
		\frac{d^2 \mathcal{F}(\delta_t)}{dt^2} =& \int \phi(X)^THf_t(\pi_t(X))\phi(X)d\nu(X)\\ 
		&+\int \phi(X)^T\nabla_x\nabla_y k(\pi_t(X),\pi_t(X')) ) \phi(X')d\nu(X)d\nu(X') 
	\end{align*}
where $Hf_t$ is the hessian of $f_t$ in space and  $\nabla_x\nabla_y k(x,y)$ is the cross diagonal term of the hessian of $k$. By \ref{assump:bounded_hessian}, the first term in the above equation can be easily upper-bounded by:
\begin{align*}
	4L \int \Vert \phi(X)\Vert^2d\nu(X)  
\end{align*}
The last term can also be upper-bounded by $2L$ by \ref{assump:bounded_trace}.
\end{proof}

Let $  \nu$ and $\nu'$ be two distributions and $\Pi$ a coupling between $\nu$ and $\nu'$. We consider the path $\rho_t$ defined as $\rho_t=(\pi_t)_{\#}\Pi$ where $\pi_t(X,Y)=(1-t)X+tY$. It is possible to provide an expression for the time derivative of $\mathcal{F}{\rho_t}$. This is given by ?\\

%\begin{lemma}\label{lem:time_derivative}
%The time derivative of $\mathcal{F}(\rho_t)$ is given by:
%	\begin{align*}
%		\frac{d \mathcal{F}(\rho_t)}{dt}&=\int \nabla f_t(\pi_t(X)).(Y-X)d\Pi(X,Y)\\
%	\end{align*}
%	where $f_t$ is the witness function at time $t$ and is given by:
%	\begin{align}
%	f_t(x)=\rho_t(k(X,x))-\mu(k(X,x)) \qquad \forall t\in [0,1]
%	\end{align}	
%\end{lemma}
%\begin{proof}
%	The proof is very similar to the one in \cref{lem:derivative_mmd}. Indeed we still have
%	\begin{align*}
%		\frac{d \mathcal{F}(\rho_t)}{dt} = \langle f_t , \frac{df_t}{dt} \rangle
%	\end{align*}
%	And the time derivative of $f_t$ at each point $x\in\mathbb{R}^d$ is obtained by direct computation:
%	\begin{align*}
%		 \frac{df_t}{dt}= \int \nabla k(\pi_t(X,Y),.).(Y-X)d\Pi(X,Y)
%	\end{align*}
%	The result follows using the reproducing property in $\kH$.
% \end{proof}






\begin{proposition}\label{prop:decreasing_functional}
	Under \cref{assump:bounded_trace,assump:bounded_hessian}, the following inequality holds:
	\begin{align*}
	\F(\nu_{n+1})-\F(\nu_n)\leq -\gamma (1-\frac{\gamma}{2}L )\int \Vert \phi_n(X)\Vert^2 d\nu_n
	\end{align*}
\end{proposition}

\begin{proof}
	
	Here we consider a path between $\nu_n$ and $\nu_{n+1}$ of the form:
	\begin{align*}
	\rho_t	=(I-\gamma t\phi_n)_{\#}\nu_n
	\end{align*}
	The function $t\mapsto \mathcal{F}(\rho_t)$ is twice differentiable, hence one can use a Taylor expansion with integral remainder to get:
	\begin{align}\label{eq:taylor_expansion}
	\mathcal{F}(\nu_{n+1})-\mathcal{F}(\nu_{n})=\mathcal{F}(\rho_1)-\mathcal{F}(\rho_0) = \frac{d \mathcal{F}(\rho_t) }{dt}\vert_{t=0}+ \frac{1}{2} \int_0^1 \frac{d^2 \mathcal{F}(\rho_t)}{dt^2}(1-t)^2 dt 
	\end{align} 
	By taking $\phi=-\gamma \phi_n$ in \cref{lem:derivative_mmd} we have that:
	\begin{align*}
	\frac{d \mathcal{F}(\rho_t) }{dt} = -\gamma \int \nabla f_n(X).\phi_n(X)d\nu_n(X)=-\gamma \int \Vert \phi_n(X) \Vert^2 d\nu_n(X)
	\end{align*}
	since $\nabla f_n=\phi_n$.
	Moreover, by \cref{assump:bounded_trace,assump:bounded_hessian} it follows from \cref{lem:derivative_mmd} that:
	\begin{align}\label{eq:upper_bound_1}
	\vert \frac{d^2 \mathcal{F}(\rho_t) }{dt^2}   \vert\leq L\int \Vert \phi_n(X) \Vert^2 d\nu_n(X)
	\end{align}
	Using \cref{eq:taylor_expansion,eq:upper_bound_1} the result follows.
\end{proof}

\vspace*{1cm}

\begin{lemma}\label{lem:mixture_convexity}
	The functional $\F$ is mixture convex: for any probability distributions $\nu_1$ and $\nu_2$ and scalar $1\leq \lambda\leq 1$:
	\begin{align*}
	\F(\lambda \nu_1+(1-\lambda)\nu_2)\leq \lambda \F(\nu_1)+ (1-\lambda)\F(\nu_2)
	\end{align*}
\end{lemma}
\begin{proof}
	Let $\nu$ and $\nu'$ be two probability distributions and $0\leq \lambda\leq 1$.
	We need to show that \[\mathcal{F}(\lambda \nu + (1-\lambda)\nu') -\lambda \mathcal{F}(\nu) -(1-\lambda)\mathcal{F}(\nu')\leq 0\]
	This follows from a simple computation which shows that:
	\begin{align*}
	\mathcal{F}(\lambda \nu + (1-\lambda)\nu') -\lambda \mathcal{F}(\nu) -(1-\lambda)\mathcal{F}(\nu') = -\frac{1}{2}\lambda(1-\lambda)MMD(\nu,\nu')^2 \leq 0.
	\end{align*}
\end{proof}


\subsection{Lojasiewicz type inequality}

Here we would like to derive an inequality between the time derivative of the Lyapounov functional $\mathcal{F}$ along its gradient flow $t\mapsto \nu_t$. For this purpose we first introduce the weighted negative Sobolev distance \manote{cite villani and peyre and Mroueh}:

\begin{align}\label{eq:neg_sobolev}
	\Vert \nu - \mu \Vert_{\dot{H}^{-1}(\nu)} = \sup_{\substack{ f\in W_0^{1,2}(\nu) \\ \nu(\Vert \nabla f \Vert^2) \leq 1 }} \vert \nu(f)-\mu(f)\vert 
\end{align}
Where $W_0^{1,2}(\nu)$ is the space $1$ order Sobolev functions with functions vanishing at the boundary of the domain.
The distance defined in \cref{eq:neg_sobolev} plays a fundamental role in dynamic optimal transport as it linearizes the $W_2$ distance when $\mu$ is arbitrarily close to $\nu$. It can also be seen as the minimum kinetic energy needed to advect the mass $\nu$ to $\mu$. However, this quantity might be infinite \manote{say exactly when it is finite} and one of the key problems would be to control its value during the evolution of the flow. More precisely we will rely on the following statement:
\begin{align}\label{eq:bounded_neg_sobolev}
	\Vert \nu_t  - \mu \Vert_{\dot{H}^{-1}(\nu_t)} \leq C \qquad \forall t\geq 0.
\end{align} 
where $\nu_t$ is defined by the gradient flow and $\mu$ is the target distribution. When \cref{eq:bounded_neg_sobolev}  holds, we have the following proposition:
\begin{proposition}\label{prop:PL_type_inequality}
	When \cref{eq:bounded_neg_sobolev} holds, the following inequality is then satisfied at all times:
	\begin{align}\label{eq:PL_type_inequality}
		\Vert \nabla f_t \Vert_{L_2(\nu_t)} \geq \frac{1}{C} \Vert f_t \Vert^2_{\mathcal{H}} \qquad \forall t\geq 0.
	\end{align}
\end{proposition}
\begin{proof}
	Indeed, this follows simply from the definition of the negative Sobolev distance: Consider $g = \Vert \nabla f_t\Vert^{-1}_{L_2(\nu_t)} f_t$, then $g\in W_0^{1,2}(\nu)$ \manote{this suggests an assumption on the kernel so that all those function satisfy a boundary condition} and $\Vert \nabla g \Vert_{L_2(\nu_t)}\leq 1$. Therefore, we directly have:
	\begin{align}
		\Vert \nu_t - \mu\Vert_{\dot{H}^{-1}(\nu_t)}\geq \vert \nu_t(g) - \mu(g)  \vert.
	\end{align}
Now, recall the definition of $g$, which implies that
\[
\vert \nu_t(g) - \mu(g)  \vert = \Vert \nabla f_t\Vert^{-1}_{L_2(\nu_t)} \vert \nu_t(f_t)-\mu(f_t)\vert.
\]
But since $f_t$  is exactly the witness functions between $\nu_t$ and $\mu$, it follows that $\nu_t(f_t)-\mu(f_t) = \Vert f_t\Vert^2_{\kH}$.
Using \cref{eq:bounded_neg_sobolev}, we get the desired inequality.
\end{proof}

Now we will use the inequality in \cref{prop:PL_type_inequality} to prove a convergence result towards the global optimum $\mu$. This is provided in \cref{prop:convergence}.

\begin{proposition}\label{prop:convergence}
	If \cref{eq:bounded_neg_sobolev} is satisfied for all times then $t\mapsto \mathcal{F}(\nu_t)$ converges to $0$ with a rate of convergence given by:
	\begin{align}
		\mathcal{F}(\nu_t)\leq \frac{1}{\mathcal{F}(\nu_0)^{-1} + \frac{4t}{C}}
	\end{align}
\end{proposition}
\begin{proof}
	The proof is a simple consequence of \cref{prop:mmd_flow,eq:bounded_neg_sobolev}. Indeed, by \cref{prop:mmd_flow} we have that 
	\begin{align}
		\dot{\F}(\nu_t) = - \Vert \nabla f_t \Vert^2_{L_2(\nu_t)} 	
	\end{align}
	Using \cref{eq:PL_type_inequality}, we directly get that:
	\begin{align}
		\dot{\F}(\nu_t) \leq  -\frac{4}{C}\F(\nu_t)^2
	\end{align}
It is clear that if $\mathcal{F}(\nu_0)>0$ then $\F(\nu_t)>0$ at all times by uniqueness of the solution. Hence, one can divide by $\F(\nu_t)^2$ and integrate the inequality from $0$ to some time $t$. The desired inequality is obtained by simple calculations.
\end{proof}

All the difficulty is to see now when \cref{eq:bounded_neg_sobolev} holds. One possible strategy would be to start from initial $\nu_0$ such that $\Vert \nu_0  - \mu \Vert_{\dot{H}^{-1}(\nu_0)} \leq C $  for some finite positive value $C$ and then show that this property is preserved during the dynamics. It is also possible to have a time depended constant $C_t$ as long as its growth is such that:
\begin{align}
	\lim_{t\rightarrow +\infty} \int_0^t C_s^{-1}\diff s = +\infty
\end{align}
For instance $C_t$ could have up to a linear growth in time. In this case the decay of $\F(\nu_t)$ will no longer be in $\frac{1}{t}$ but only in $\frac{1}{\log(t)}$ \manote{This seems unlikely if we end up having convergence of $\nu_t$, but who nows.}.
One possible promising condition for \cref{eq:bounded_neg_sobolev} to hold would be if $\mu \ll \nu_0$ and if this property is preserved during the dynamics.


 








